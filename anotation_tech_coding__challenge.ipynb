{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcJVmm4B+WDe5KxsiUheFt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyasifred/webscraping-with-BeautifulSoup-Scrapy-and-Selenium/blob/main/anotation_tech_coding__challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVetYAxdqGEv"
      },
      "outputs": [],
      "source": [
        "url = \"https://docs.google.com/document/d/e/2PACX-1vSHesOf9hv2sPOntssYrEdubmMQm8lwjfwv6NPjjmIRYs_FOYXtqrYgjh85jBUebK9swPXh_a5TJ5Kl/pub\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from lxml import etree\n",
        "\n",
        "# Function to retrieve and parse the Google Doc data using XPath\n",
        "def get_google_doc_data(doc_url):\n",
        "    \"\"\"\n",
        "    Retrieves and parses data from a Google Doc, extracting X and Y coordinates\n",
        "    along with corresponding characters using XPath.\n",
        "\n",
        "    Args:\n",
        "        doc_url (str): The URL of the Google Doc to be processed.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tuples, each containing (x, character, y) extracted from the document.\n",
        "               If an error occurs, an empty list is returned.\n",
        "\n",
        "    Raises:\n",
        "        Exception: If there is an issue with the document retrieval or parsing.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Convert the Google Doc URL to export as plain text\n",
        "        export_url = doc_url.replace('/edit', '/export?format=html')\n",
        "\n",
        "        # Fetch the HTML content of the document\n",
        "        response = requests.get(export_url)\n",
        "\n",
        "        # Check if the request was successful\n",
        "        if response.status_code != 200:\n",
        "            raise Exception(f\"Failed to retrieve the document. Status code: {response.status_code}\")\n",
        "\n",
        "        # Parse the HTML content with lxml\n",
        "        tree = etree.HTML(response.content)\n",
        "\n",
        "        # Define XPaths for the first, second, and third columns\n",
        "        x_path_xcoord = \"//tr/td[1]//p//span/text()\"  # X-coordinate\n",
        "        x_path_char = \"//tr/td[2]//p//span/text()\"    # Character\n",
        "        x_path_ycoord = \"//tr/td[3]//p//span/text()\"  # Y-coordinate\n",
        "\n",
        "        # Extract values using XPath\n",
        "        x_coords = tree.xpath(x_path_xcoord)[1:]  # Skip the first element (header)\n",
        "        chars = tree.xpath(x_path_char)[1:]       # Skip the first element (header)\n",
        "        y_coords = tree.xpath(x_path_ycoord)[1:]  # Skip the first element (header)\n",
        "\n",
        "        # Make sure all lists are of equal length\n",
        "        if len(x_coords) != len(chars) or len(chars) != len(y_coords):\n",
        "            raise Exception(\"Mismatched data lengths between x, characters, and y.\")\n",
        "\n",
        "        table_data = []\n",
        "\n",
        "        # Extract text from the elements and convert to appropriate types\n",
        "        for i in range(len(x_coords)):\n",
        "            try:\n",
        "                x = int(x_coords[i].strip())  # Extract X-coordinate\n",
        "                # Decode the character from unicode\n",
        "                char = chars[i].strip().encode('latin1').decode('utf-8')  # Decode the character\n",
        "                y = int(y_coords[i].strip())  # Extract Y-coordinate\n",
        "\n",
        "                # Ensure char is a single character\n",
        "                if len(char) != 1:\n",
        "                    raise ValueError(f\"Expected a single character but got: '{char}'\")\n",
        "\n",
        "                # Append the parsed (x, char, y) tuple to the table_data list\n",
        "                table_data.append((x, char, y))\n",
        "\n",
        "            except ValueError as ve:\n",
        "                print(f\"Error processing row {i}: {ve}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Unexpected error processing row {i}: {e}\")\n",
        "\n",
        "        if not table_data:\n",
        "            raise Exception(\"No valid data found in the table.\")\n",
        "\n",
        "        return table_data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving or parsing Google Doc: {e}\")\n",
        "        return []\n",
        "\n",
        "# Function to create and print the grid\n",
        "def print_grid_from_data(url):\n",
        "    \"\"\"\n",
        "    Creates and prints a grid representation of characters based on their X and Y coordinates\n",
        "    extracted from the specified Google Doc.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the Google Doc to retrieve data from.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        TypeError: If the provided URL is not a string or if data types are invalid.\n",
        "        ValueError: If there is a value-related issue during processing.\n",
        "        Exception: For any unexpected errors that occur during grid creation or printing.\n",
        "    \"\"\"\n",
        "    # Check if the URL is a string\n",
        "    if not isinstance(url, str):\n",
        "        raise TypeError(\"The provided URL must be a string.\")\n",
        "\n",
        "    try:\n",
        "        table_data = get_google_doc_data(url)\n",
        "\n",
        "        # Find the maximum x and y coordinates to determine grid size\n",
        "        max_x = max(data[0] for data in table_data)\n",
        "        max_y = max(data[2] for data in table_data)\n",
        "\n",
        "        # Create an empty grid filled with spaces\n",
        "        grid = [[' ' for _ in range(max_x + 1)] for _ in range(max_y + 1)]\n",
        "\n",
        "        # Place characters in the grid based on their coordinates\n",
        "        for x, char, y in table_data:\n",
        "            # Validate x and y as integers and char as a string\n",
        "            if not (isinstance(x, int) and isinstance(y, int) and isinstance(char, str)):\n",
        "                raise TypeError(f\"Invalid data types for (x, char, y): ({x}, {char}, {y})\")\n",
        "\n",
        "            grid[y][x] = char\n",
        "\n",
        "        # Print the grid row by row\n",
        "        for row in grid:\n",
        "            print(''.join(row))\n",
        "\n",
        "    except ValueError as ve:\n",
        "        print(f\"Value error: {ve}\")\n",
        "    except TypeError as te:\n",
        "        print(f\"Type error: {te}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "bsMi-mj3GDeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_grid_from_data(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT-Hw-sVGykJ",
        "outputId": "be585353-96bc-404b-b3ae-52b05ab999e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "██████████░ ██████░    ███████░     ██░     ██░     ████████░    ██░    ███░   ████████░  \n",
            "██░           ██░    ███░    ██░   ████░   ████░    ██░     ██░  ██░  ███░   ███░     ███░\n",
            "██░           ██░   ███░           ██░██░ ██░██░    ██░      ██░ ██░███░     ██░       ██░\n",
            "████████░     ██░   ██░           ███░ ██░██░ ██░   ██░      ██░ ████░       ██░       ██░\n",
            "██░           ██░   ███░          ██░  █████░ ███░  ██░      ██░ ██░███░     ██░       ██░\n",
            "██░           ██░    ███░    ██░ ███░   ███░   ██░  ██░     ██░  ██░  ███░   ███░     ███░\n",
            "██████████░ ██████░    ███████░  ██░           ███░ ████████░    ██░    ███░   ████████░  \n"
          ]
        }
      ]
    }
  ]
}